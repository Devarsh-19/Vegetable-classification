{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project-veg_classification.ipynb",
      "provenance": [],
      "mount_file_id": "1vnFsuk4dFfSneqvybCh2BtghobLQSl0e",
      "authorship_tag": "ABX9TyPhF4iH4SgYdlkd7ssYUs1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devarsh-19/Vegetable-classification/blob/main/project_veg_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRJgay-OWQKT",
        "outputId": "07a0c1fd-4ffc-4940-f75a-10306e98caf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "qGqtvHaHX5Ed",
        "outputId": "294a71d6-29f3-43fb-8231-d248b76283aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fonttools-4.33.3 matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # file directory and file sysstem ops\n",
        "import numpy as np # for nd arrays\n",
        "\n",
        "import torch  #for deep learning\n",
        "from torch import nn\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "tnij5-kMY8i1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ],
      "metadata": {
        "id": "_WPEUHtsZrCG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm #progess report and loop opertarions"
      ],
      "metadata": {
        "id": "CfNKmtfpaDF6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "dSGfwWP0aV2x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "M8QAKa5EajTG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download misrakahmed/vegetable-image-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwqRD8oaaolB",
        "outputId": "40817ec4-8ca3-4689-cef5-f620e231d508"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading vegetable-image-dataset.zip to /content\n",
            " 98% 521M/534M [00:03<00:00, 186MB/s]\n",
            "100% 534M/534M [00:03<00:00, 173MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq vegetable-image-dataset.zip"
      ],
      "metadata": {
        "id": "-f7YQFFXawGQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv Vegtable\\ Images Vegetable Images "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1VbAAiCcR9S",
        "outputId": "7a0bccf5-e0e9-4e29-926a-8128185fcfd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: target 'Images' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA\n",
        "--------------------\n",
        "STEP 1 : Find number of classes and number of images in each class  \n",
        "STEP 2 : Size Analysis - heights, widths, resolutions, aspect rations  \n",
        "STEP 3 : Look for blurred images  \n",
        "STEP 4 : Look for low contrast images  \n",
        "STEP 5 : Look for noisy images  \n",
        "STEP 6 : Look for bright and dark images  \n"
      ],
      "metadata": {
        "id": "7d95QDBrfEO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_vegetables = datasets.ImageFolder(\"Vegetable Images/train\",transform = None)\n",
        "val_vegetables = datasets.ImageFolder(\"Vegetable Images/validation\",transform = None)\n",
        "test_vegetables = datasets.ImageFolder(\"Vegetable Images/test\",transform = None)"
      ],
      "metadata": {
        "id": "RF3OizSLfbG8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vegetables), print(val_vegetables), print(test_vegetables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFm9mO2ffmxe",
        "outputId": "4b0c5850-aa7a-4a5a-9d26-9abf35c596c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 15000\n",
            "    Root location: Vegetable Images/train\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 3000\n",
            "    Root location: Vegetable Images/validation\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 3000\n",
            "    Root location: Vegetable Images/test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vegetable_classes = train_vegetables.classes\n",
        "print(f\"Classes: {vegetable_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J_hhHBZgUIl",
        "outputId": "350d1714-3ca7-436b-93c3-d255a8abb40a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No. of classes: {}\".format(len(vegetable_classes)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szfT1cDghMGN",
        "outputId": "b94f2bea-4f69-402e-9307-2226765c5cbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of classes: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = train_vegetables.targets"
      ],
      "metadata": {
        "id": "nDBfOg-4hVnd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_strength = np.unique(targets, return_counts= True)"
      ],
      "metadata": {
        "id": "6l1F7Cldq7n0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_strength"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hdeJFrrB_S",
        "outputId": "b9381884-0984-47e0-dcfb-32adb1378b1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
              " array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
              "        1000, 1000, 1000, 1000]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA: STEP 2"
      ],
      "metadata": {
        "id": "CSXBybWOrsXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "widths = []\n",
        "heights = []\n",
        "resolutions = []\n",
        "aspect_ratios = []\n",
        "imgs = []\n",
        "\n",
        "for i in tqdm(range(len(train_vegetables.imgs))):\n",
        "  img_path, label = train_vegetables.imgs[i]\n",
        "  img = Image.open(img_path)\n",
        "  w, h = img.size\n",
        "\n",
        "  imgs.append(img_path)\n",
        "  heights.append(h)\n",
        "  widths.append(w)\n",
        "  resolutions.append(h*w)\n",
        "  aspect_ratios.append(w/h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RWg9NulrYnT",
        "outputId": "8725ad70-3b84-438c-f52b-f6b765561cb6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15000/15000 [00:03<00:00, 3794.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(heights))\n",
        "print(min(heights), max(heights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcCbqihOvene",
        "outputId": "959e463a-1dd4-4d89-9f3a-7d6af0c85cf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000\n",
            "193 224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard resolution used to train the neural network images is 128 by 128.   \n",
        "for 1st image 128 x 128  \n",
        "for 2nd 224 x 224  \n",
        "for 3rd 256 x 256 and so on  \n",
        "make sure to keep resolution below 400 x 400  \n",
        "\n",
        "IMAGE AUGMENTATION -> maipulate image data"
      ],
      "metadata": {
        "id": "DC4ht7L0vnKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((224,224)),\n",
        "                                transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#on colab\n",
        "\n",
        "train_vegetables = datasets.ImageFolder(\"Vegetable Images/train\",transform = transform)\n",
        "val_vegetables = datasets.ImageFolder(\"Vegetable Images/validation\",transform = transform)\n",
        "test_vegetables = datasets.ImageFolder(\"Vegetable Images/test\",transform = transform)"
      ],
      "metadata": {
        "id": "pGeDHVbRw7l6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vegetables), print(val_vegetables), print(test_vegetables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tXjdoqBxG8-",
        "outputId": "1d3163d9-fb5d-4c89-b7fb-ca42dceeb81e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 15000\n",
            "    Root location: Vegetable Images/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 3000\n",
            "    Root location: Vegetable Images/validation\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 3000\n",
            "    Root location: Vegetable Images/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA SAMPLER AND RANDOM SAMPLING  \n",
        "CUDA - Compute Unified Device Architecture\n",
        "Validataion Data - Ground Truth"
      ],
      "metadata": {
        "id": "aPNWnHWQy7jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "TvK-ahT3zNFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20582d98-4984-4df2-a80a-8bed2c5a8b8c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_vegetables,\n",
        "                                      batch_size = 32,\n",
        "                                      shuffle = True,\n",
        "                                      pin_memory = True)"
      ],
      "metadata": {
        "id": "DpZjNEJdzRSi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_vegetables,\n",
        "                                      batch_size = 45,\n",
        "                                      shuffle = False,\n",
        "                                      pin_memory = True)"
      ],
      "metadata": {
        "id": "GU0PGo-pzVHo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(val_vegetables,\n",
        "                                      batch_size = 40,\n",
        "                                      shuffle = False,\n",
        "                                      pin_memory = True)"
      ],
      "metadata": {
        "id": "nIeErnx22huG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader)), print(len(test_loader)), print(len(val_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml7pSh184cQx",
        "outputId": "528ac316-05c8-4438-e294-ac53acbb31a5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469\n",
            "67\n",
            "75\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the sequential object\n",
        "\n",
        "my_cnn_classifier = nn.Sequential()"
      ],
      "metadata": {
        "id": "ETFbCK9F4gPA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING CNN LAYERS\n",
        "\n",
        "#Add a CNN Set\n",
        "\n",
        "#Convolution -> ReLU -> Pooling\n",
        "\n",
        "\n",
        "conv_layer_1 = nn.Conv2d(in_channels= 3, out_channels= 32, kernel_size = 7, stride = 1, padding= 0, bias = True);\n",
        "\n",
        "my_cnn_classifier.add_module(\"conv_layer_1\", conv_layer_1)\n",
        "\n",
        "act_1 = nn.ReLU();\n",
        "my_cnn_classifier.add_module(\"act_1\",act_1);\n",
        "\n",
        "pool_1 = nn.AvgPool2d(kernel_size= 2, stride = 2,padding = 0);\n",
        "\n",
        "my_cnn_classifier.add_module(\"pool_1\",pool_1)"
      ],
      "metadata": {
        "id": "uTrQ76NRyzym"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "print(summary(my_cnn_classifier, (3,224,224), device = \"cpu\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWVhZAoQ0FVE",
        "outputId": "0ae73820-5608-49dc-9af5-7e64993739bf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 218, 218]           4,736\n",
            "              ReLU-2         [-1, 32, 218, 218]               0\n",
            "         AvgPool2d-3         [-1, 32, 109, 109]               0\n",
            "================================================================\n",
            "Total params: 4,736\n",
            "Trainable params: 4,736\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 26.11\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 26.70\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QzFlRReZ0N4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}